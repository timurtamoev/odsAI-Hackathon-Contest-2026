{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "40201b99",
      "metadata": {},
      "source": [
        "# Book Recommendation Hackathon \n",
        "\n",
        "**Task:** Rank 20 editions for each user from 200 candidates, optimizing Score = 0.7×NDCG@20 + 0.3×Diversity@20\n",
        "\n",
        "**Strategy - classic, catboost ranker + rearranging (for the 30% of the residual metric bcs catboost is fitted on ndcg)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2f12d9fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys \n",
        "import os\n",
        "import warnings \n",
        "\n",
        "os.environ['OPENBLUS_NUM_THREADS'] = '1'\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a59468ea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all data frames have been loaded successfully\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import numpy as np\n",
        "\n",
        "interactions = pd.read_csv('data/interactions.csv')\n",
        "editions = pd.read_csv('data/editions.csv')\n",
        "users = pd.read_csv('data/users.csv')\n",
        "book_genres = pd.read_csv('data/book_genres.csv')\n",
        "genres = pd.read_csv('data/genres.csv')\n",
        "authors = pd.read_csv('data/authors.csv') \n",
        "target_users = pd.read_csv('submit/targets.csv') \n",
        "target_interactions = pd.read_csv('submit/candidates.csv')\n",
        "\n",
        "print('all data frames have been loaded successfully')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c4ebdc28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 37 ms, sys: 12.8 ms, total: 49.8 ms\n",
            "Wall time: 61.3 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "interactions['event_ts'] = pd.to_datetime(interactions['event_ts'])\n",
        "\n",
        "split_date = pd.Timestamp('2025-03-12')\n",
        "\n",
        "feature_source = interactions.loc[interactions['event_ts'] < split_date]\n",
        "train = interactions.loc[interactions['event_ts'] > split_date]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4b51281d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 1.96 s, sys: 199 ms, total: 2.16 s\n",
            "Wall time: 2.19 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "book_genres = book_genres.groupby('book_id')['genre_id'].apply(lambda x: ' '.join(x.astype(str))).reset_index()\n",
        "enriched_editions = editions.merge(book_genres, on='book_id')\n",
        "\n",
        "enriched_editions['author_productivity']= enriched_editions.author_id.map(enriched_editions.author_id.value_counts())\n",
        "\n",
        "feature_source = feature_source.drop('event_ts', axis=1)\n",
        "feature_source = feature_source.merge(users, on='user_id')\n",
        "feature_source = feature_source.merge(enriched_editions, on='edition_id')\n",
        "\n",
        "feature_source = feature_source.drop('book_id', axis=1) #1 to 1 with edition_id\n",
        "feature_source = feature_source.drop('publisher_id', axis=1) #1 to 1 with edition_id\n",
        "\n",
        "feature_source['edition_popularity_score'] = feature_source.edition_id.map(feature_source.edition_id.value_counts())\n",
        "feature_source['reader_mean_age'] = feature_source.groupby('edition_id')['age'].transform('mean')\n",
        "feature_source['book_age'] = 2026 - feature_source['publication_year']\n",
        "feature_source['user_mean_rating'] = feature_source.groupby('user_id')['rating'].transform('mean')\n",
        "feature_source['book_mean_rating'] = feature_source.groupby('edition_id')['rating'].transform('mean')\n",
        "feature_source = feature_source.drop('rating', axis=1)\n",
        "\n",
        "user_cols = ['user_id', 'gender', 'age', 'user_mean_rating']\n",
        "\n",
        "user_features = feature_source[user_cols].drop_duplicates().reset_index()\n",
        "user_features = user_features.drop('index', axis=1)\n",
        "\n",
        "book_features = feature_source[[f for f in feature_source.columns.to_list() if f not in user_cols]].drop_duplicates().reset_index()\n",
        "book_features = book_features.drop(['event_type', 'index'], axis=1)\n",
        "book_features = book_features.drop_duplicates()\n",
        "\n",
        "train = train.merge(book_features, on='edition_id').merge(user_features, on='user_id')\n",
        "train = train.drop(['event_ts', 'rating'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e513b3ed",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>edition_id</th>\n",
              "      <th>event_type</th>\n",
              "      <th>author_id</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>age_restriction</th>\n",
              "      <th>language_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>genre_id</th>\n",
              "      <th>author_productivity</th>\n",
              "      <th>edition_popularity_score</th>\n",
              "      <th>reader_mean_age</th>\n",
              "      <th>book_age</th>\n",
              "      <th>book_mean_rating</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>user_mean_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>560</td>\n",
              "      <td>1010822636</td>\n",
              "      <td>2</td>\n",
              "      <td>507926.0</td>\n",
              "      <td>2024</td>\n",
              "      <td>16</td>\n",
              "      <td>119</td>\n",
              "      <td>Призраки белых ночей</td>\n",
              "      <td>На встрече бывших однокурсников Александра ста...</td>\n",
              "      <td>1222 1224 1309</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>37.857143</td>\n",
              "      <td>2</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.733333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  edition_id  event_type  author_id  publication_year  \\\n",
              "0      560  1010822636           2   507926.0              2024   \n",
              "\n",
              "   age_restriction  language_id                 title  \\\n",
              "0               16          119  Призраки белых ночей   \n",
              "\n",
              "                                         description        genre_id  \\\n",
              "0  На встрече бывших однокурсников Александра ста...  1222 1224 1309   \n",
              "\n",
              "   author_productivity  edition_popularity_score  reader_mean_age  book_age  \\\n",
              "0                   56                         7        37.857143         2   \n",
              "\n",
              "   book_mean_rating  gender  age  user_mean_rating  \n",
              "0          7.571429     2.0  9.0          7.733333  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3307b505",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 66.2 ms, sys: 107 ms, total: 173 ms\n",
            "Wall time: 194 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Настройки\n",
        "NEGATIVE_FRACTION = 3\n",
        "needed_cols = [\n",
        "    'user_id', 'edition_id', 'event_type', 'gender', 'age', 'author_id', \n",
        "    'publication_year', 'age_restriction', 'language_id', 'title', \n",
        "    'description', 'genre_id', 'author_productivity', \n",
        "    'edition_popularity_score', 'reader_mean_age', 'book_age', \n",
        "    'user_mean_rating', 'book_mean_rating'\n",
        "]\n",
        "\n",
        "# 2. Подготовка количества сэмплов для каждого юзера\n",
        "# Вычисляем, сколько негативных примеров нужно каждому пользователю\n",
        "num_negative_samples_per_user = train['user_id'].value_counts() * NEGATIVE_FRACTION\n",
        "max_books = len(book_features)\n",
        "num_negative_samples_per_user = num_negative_samples_per_user.clip(upper=max_books)\n",
        "\n",
        "# 3. Подготовка признаков пользователей (для быстрого джойна)\n",
        "_user_cols = ['user_id', 'gender', 'age', 'user_mean_rating']\n",
        "_user_features = train[_user_cols].drop_duplicates(subset=['user_id']).set_index('user_id')\n",
        "\n",
        "# 4. Генерация массивов для сэмплирования\n",
        "user_ids = num_negative_samples_per_user.index.to_numpy()\n",
        "counts = num_negative_samples_per_user.to_numpy()\n",
        "\n",
        "# Создаем длинный массив user_id, где каждый ID повторяется N раз\n",
        "repeated_user_ids = np.repeat(user_ids, counts)\n",
        "total_samples = len(repeated_user_ids)\n",
        "\n",
        "# 5. СЛУЧАЙНЫЙ ВЫБОР КНИГ (вместо сортировки по популярности)\n",
        "# Генерируем случайные индексы книг\n",
        "random_indices = np.random.randint(0, max_books, size=total_samples)\n",
        "\n",
        "# Выбираем книги по этим случайным индексам\n",
        "# reset_index нужен, чтобы iloc работал корректно с 0 до max_books\n",
        "sampled_books = book_features.reset_index(drop=True).iloc[random_indices].reset_index(drop=True)\n",
        "\n",
        "# 6. Подтягиваем данные пользователей\n",
        "sampled_users = _user_features.loc[repeated_user_ids].reset_index(drop=True)\n",
        "\n",
        "# 7. Сборка датафрейма с негативными примерами\n",
        "negativity_builder = pd.concat([sampled_users, sampled_books], axis=1)\n",
        "negativity_builder['user_id'] = repeated_user_ids\n",
        "negativity_builder['event_type'] = 0  # Маркируем как негативный пример\n",
        "negativity_builder = negativity_builder[needed_cols]\n",
        "\n",
        "# 8. Объединение с основным трейном и чистка\n",
        "train = pd.concat([train, negativity_builder], ignore_index=True)\n",
        "\n",
        "# Сортируем так, чтобы реальные события (event_type != 0) были выше\n",
        "train = train.sort_values(by='event_type', ascending=False)\n",
        "\n",
        "# Удаляем дубликаты.\n",
        "# Если случайная книга оказалась той, которую юзер реально читал,\n",
        "# благодаря сортировке мы оставим верхнюю запись (реальную), а нижнюю (фейковую) удалим.\n",
        "train = train.drop_duplicates(subset=['user_id', 'edition_id'], keep='first')\n",
        "\n",
        "# Финальное форматирование\n",
        "train.edition_id = train.edition_id.astype(str)\n",
        "train = train.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "197a82e1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>edition_id</th>\n",
              "      <th>event_type</th>\n",
              "      <th>author_id</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>age_restriction</th>\n",
              "      <th>language_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>genre_id</th>\n",
              "      <th>author_productivity</th>\n",
              "      <th>edition_popularity_score</th>\n",
              "      <th>reader_mean_age</th>\n",
              "      <th>book_age</th>\n",
              "      <th>book_mean_rating</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>user_mean_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>560</td>\n",
              "      <td>1010822636</td>\n",
              "      <td>2</td>\n",
              "      <td>507926.0</td>\n",
              "      <td>2024</td>\n",
              "      <td>16</td>\n",
              "      <td>119</td>\n",
              "      <td>Призраки белых ночей</td>\n",
              "      <td>На встрече бывших однокурсников Александра ста...</td>\n",
              "      <td>1222 1224 1309</td>\n",
              "      <td>56</td>\n",
              "      <td>7</td>\n",
              "      <td>37.857143</td>\n",
              "      <td>2</td>\n",
              "      <td>7.571429</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.733333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7163500</td>\n",
              "      <td>1007326489</td>\n",
              "      <td>2</td>\n",
              "      <td>2011018.0</td>\n",
              "      <td>2022</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>Клара и 11 бабушек</td>\n",
              "      <td>Кларе 9 лет и она живет с дедушкой-трубочистом...</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.628571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7168360</td>\n",
              "      <td>1012387985</td>\n",
              "      <td>2</td>\n",
              "      <td>1199919.0</td>\n",
              "      <td>2025</td>\n",
              "      <td>18</td>\n",
              "      <td>119</td>\n",
              "      <td>Мальчики в долине</td>\n",
              "      <td>Конец XIX века, горная долина в штате Пенсильв...</td>\n",
              "      <td>1223</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>35.333333</td>\n",
              "      <td>1</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>7.347826</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  edition_id  event_type  author_id  publication_year  \\\n",
              "0      560  1010822636           2   507926.0              2024   \n",
              "1  7163500  1007326489           2  2011018.0              2022   \n",
              "2  7168360  1012387985           2  1199919.0              2025   \n",
              "\n",
              "   age_restriction  language_id                 title  \\\n",
              "0               16          119  Призраки белых ночей   \n",
              "1               18            0    Клара и 11 бабушек   \n",
              "2               18          119     Мальчики в долине   \n",
              "\n",
              "                                         description        genre_id  \\\n",
              "0  На встрече бывших однокурсников Александра ста...  1222 1224 1309   \n",
              "1  Кларе 9 лет и она живет с дедушкой-трубочистом...             137   \n",
              "2  Конец XIX века, горная долина в штате Пенсильв...            1223   \n",
              "\n",
              "   author_productivity  edition_popularity_score  reader_mean_age  book_age  \\\n",
              "0                   56                         7        37.857143         2   \n",
              "1                    1                         1        31.000000         4   \n",
              "2                    2                        10        35.333333         1   \n",
              "\n",
              "   book_mean_rating  gender   age  user_mean_rating  \n",
              "0          7.571429     2.0   9.0          7.733333  \n",
              "1               NaN     2.0  11.0          9.628571  \n",
              "2          6.000000     2.0  28.0          7.347826  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d983da76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер групп в трейне: 26.79 книг на юзера\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostRanker, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "cat_features = [\n",
        "    'gender', \n",
        "    'author_id', \n",
        "]\n",
        "\n",
        "text_features = [\n",
        "    'title', \n",
        "    'description', \n",
        "    'genre_id'\n",
        "]\n",
        "# Сбрасываем индекс СРАЗУ, чтобы он был 0, 1, 2... везде\n",
        "train = train.sort_values('user_id').reset_index(drop=True)\n",
        "\n",
        "# 2. Выделяем группы (Queries) и таргет (Label) ПЕРЕД удалением колонок\n",
        "queries = train['user_id']\n",
        "label = train['event_type']\n",
        "\n",
        "# 3. Готовим признаки (X) - удаляем ВСЁ лишнее тут\n",
        "# ВАЖНО: Убираем user_id отсюда, чтобы не было лика!\n",
        "drop_cols = ['event_type', 'edition_id', 'user_id', \n",
        "             'edition_popularity_score', 'user_mean_rating', \n",
        "             'book_mean_rating', 'reader_mean_age']          \n",
        "X = train.drop(columns=drop_cols)\n",
        "\n",
        "# 4. Приводим категории к строкам\n",
        "cat_features_safe = ['author_id', 'language_id', 'gender', 'genre_id'] \n",
        "for col in cat_features_safe:\n",
        "    X[col] = X[col].astype(str).replace('nan', 'unknown')\n",
        "\n",
        "# 5. МАГИЧЕСКИЙ СПЛИТ: Передаем X, y и queries ВМЕСТЕ\n",
        "# shuffle=False обязателен для ранкера, чтобы не разорвать группы юзеров\n",
        "X_train, X_test, y_train, y_test, q_train, q_test = train_test_split(\n",
        "    X, label, queries, \n",
        "    test_size=0.33, \n",
        "    random_state=42, \n",
        "    shuffle=False \n",
        ")\n",
        "\n",
        "# 6. Проверка на вшивость (Обязательно посмотри этот принт!)\n",
        "print(f\"Размер групп в трейне: {q_train.value_counts().mean():.2f} книг на юзера\")\n",
        "# Если тут будет 1.0 — значит данные кривые. Должно быть 5-10-20.\n",
        "\n",
        "# Заполни пустоты во ВСЕХ текстовых признаках\n",
        "text_cols = ['title', 'description', 'genre_id'] # проверь список по своему коду\n",
        "\n",
        "for col in text_cols:\n",
        "    X_train[col] = X_train[col].fillna('none').astype(str)\n",
        "    X_test[col] = X_test[col].fillna('none').astype(str)\n",
        "\n",
        "# Теперь создавай Pool\n",
        "train_pool = Pool(\n",
        "    data=X_train,\n",
        "    label=y_train,\n",
        "    group_id=q_train,\n",
        "    cat_features=cat_features,\n",
        "    text_features=text_features\n",
        ")\n",
        "\n",
        "val_pool = Pool(\n",
        "    data=X_test, label=y_test, group_id=q_test,\n",
        "    cat_features=cat_features_safe, text_features=text_cols\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "43c031b9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82330a0e24ab4bb29fa904ff25f15d5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Groupwise loss function. OneHotMaxSize set to 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\ttest: 0.2957117\tbest: 0.2957117 (0)\ttotal: 230ms\tremaining: 3m 49s\n",
            "100:\ttest: 0.2719063\tbest: 0.2957117 (0)\ttotal: 19.1s\tremaining: 2m 49s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.2957117316\n",
            "bestIteration = 0\n",
            "\n",
            "Shrink model to first 1 iterations.\n",
            "CPU times: user 2min 4s, sys: 5.19 s, total: 2min 9s\n",
            "Wall time: 21 s\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRanker at 0x3300ea360>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "from catboost import CatBoostRanker\n",
        "\n",
        "TASK_TYPE = 'CPU'\n",
        "\n",
        "model = CatBoostRanker(\n",
        "    iterations=1000, \n",
        "    learning_rate=0.1, \n",
        "    loss_function='YetiRank', \n",
        "    eval_metric='NDCG:top=20', \n",
        "    random_seed=42, \n",
        "    task_type=TASK_TYPE, \n",
        "    metric_period=100, \n",
        "    use_best_model=True, \n",
        "    early_stopping_rounds=100\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    train_pool,\n",
        "    eval_set=val_pool, \n",
        "    plot=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "36dba017",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is model trained: True\n",
            "                feature  importance\n",
            "5           description    0.016096\n",
            "4                 title    0.007363\n",
            "10                  age    0.002044\n",
            "7   author_productivity    0.001471\n",
            "0             author_id    0.001300\n",
            "3           language_id    0.000212\n",
            "2       age_restriction    0.000159\n",
            "9                gender   -0.000020\n",
            "1      publication_year   -0.000204\n",
            "8              book_age   -0.000240\n",
            "6              genre_id   -0.009451\n"
          ]
        }
      ],
      "source": [
        "# 1. Проверяем, что модель обучена. Если выведет True, значит всё ок.\n",
        "print(f\"Is model trained: {model.is_fitted()}\")\n",
        "\n",
        "# 2. Явно запрашиваем важность\n",
        "importances = model.get_feature_importance(train_pool)\n",
        "feature_names = model.feature_names_\n",
        "\n",
        "# 3. Собираем таблицу\n",
        "fea_imp = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'importance': importances\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "print(fea_imp)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
