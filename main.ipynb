{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-07T17:26:35.810562Z",
          "iopub.status.busy": "2026-02-07T17:26:35.809442Z",
          "iopub.status.idle": "2026-02-07T17:26:36.223456Z",
          "shell.execute_reply": "2026-02-07T17:26:36.222178Z",
          "shell.execute_reply.started": "2026-02-07T17:26:35.810471Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interactions = pd.read_csv(\"data/interactions.csv\")\n",
        "users = pd.read_csv(\"data/users.csv\")\n",
        "editions = pd.read_csv(\"data/editions.csv\")\n",
        "authors = pd.read_csv(\"data/authors.csv\")\n",
        "genres = pd.read_csv(\"data/genres.csv\")\n",
        "book_genres = pd.read_csv(\"data/book_genres.csv\")\n",
        "\n",
        "book_genre_names = (\n",
        "    book_genres.merge(genres, on=\"genre_id\")\n",
        "    .groupby(\"book_id\")[\"genre_name\"]\n",
        "    .apply(list)\n",
        "    .reset_index()\n",
        ")\n",
        "book_genre_names.columns = [\"book_id\", \"genre_names\"]\n",
        "\n",
        "data = (\n",
        "    interactions\n",
        "    .merge(editions, on=\"edition_id\", how=\"left\")\n",
        "    .merge(authors, on=\"author_id\", how=\"left\")\n",
        "    .merge(users, on=\"user_id\", how=\"left\")\n",
        "    .merge(book_genre_names, on=\"book_id\", how=\"left\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"event_ts\"] = pd.to_datetime(data[\"event_ts\"])\n",
        "max_ts = data[\"event_ts\"].max()\n",
        "cutoff_ts = max_ts - pd.Timedelta(days=30)\n",
        "future_data = data[data[\"event_ts\"] >= cutoff_ts].copy()\n",
        "data = data[data[\"event_ts\"] < cutoff_ts].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for CatBoost: fill NaN so model can fit (string/object -> \"none\", cat cols -> int, rest numeric -> sentinel)\n",
        "CAT_COLS = [\"author_id\", \"language_id\", \"publisher_id\", \"age_restriction\"]\n",
        "\n",
        "def fit_data_for_catboost(df):\n",
        "    out = df.copy()\n",
        "    for col in out.columns:\n",
        "        if col in CAT_COLS:\n",
        "            # CatBoost requires cat_features to be int or string, not float\n",
        "            out[col] = pd.to_numeric(out[col], errors=\"coerce\").fillna(-1).astype(int)\n",
        "        elif out[col].dtype == object or pd.api.types.is_string_dtype(out[col]):\n",
        "            out[col] = out[col].fillna(\"none\").astype(str).replace(\"nan\", \"none\")\n",
        "        elif pd.api.types.is_integer_dtype(out[col]):\n",
        "            out[col] = out[col].fillna(-1)\n",
        "        elif pd.api.types.is_float_dtype(out[col]):\n",
        "            out[col] = out[col].fillna(0.0)\n",
        "    return out\n",
        "\n",
        "data = fit_data_for_catboost(data)\n",
        "future_data = fit_data_for_catboost(future_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import log2\n",
        "from collections import defaultdict\n",
        "\n",
        "def _relevance_per_user_item(test_interactions):\n",
        "    uir = defaultdict(dict)\n",
        "    for _, row in test_interactions.iterrows():\n",
        "        u, i, e = row[\"user_id\"], row[\"edition_id\"], row[\"event_type\"]\n",
        "        if e == 2:\n",
        "            uir[u][i] = 3\n",
        "        elif e == 1 and uir.get(u, {}).get(i, 0) != 3:\n",
        "            uir[u][i] = 1\n",
        "        elif u not in uir or i not in uir[u]:\n",
        "            uir[u][i] = 0\n",
        "    return uir\n",
        "\n",
        "def _predictions_to_lists(predictions, n=20):\n",
        "    if isinstance(predictions, pd.DataFrame):\n",
        "        pred_lists = predictions.groupby(\"user_id\").apply(\n",
        "            lambda g: g.sort_values(\"rank\")[\"edition_id\"].tolist()\n",
        "        ).to_dict()\n",
        "    else:\n",
        "        pred_lists = dict(predictions)\n",
        "    return {u: (list(ids)[:n] + [None] * (n - len(ids)))[:n] for u, ids in pred_lists.items()}\n",
        "\n",
        "def ndcg_at_20(predictions, test_interactions, k=20):\n",
        "    uir = _relevance_per_user_item(test_interactions)\n",
        "    pred_lists = _predictions_to_lists(predictions, n=k)\n",
        "    ndcg_list = []\n",
        "    for user, rank_list in pred_lists.items():\n",
        "        rels = [uir[user].get(ed, 0) for ed in rank_list if ed is not None]\n",
        "        rels = (rels + [0] * k)[:k]\n",
        "        dcg = sum(r / log2(i + 2) for i, r in enumerate(rels))\n",
        "        ideal = sorted((r for r in uir[user].values()), reverse=True)[:k]\n",
        "        ideal = ideal + [0] * (k - len(ideal))\n",
        "        idcg = sum(r / log2(i + 2) for i, r in enumerate(ideal))\n",
        "        ndcg_list.append(dcg / idcg if idcg > 0 else 0.0)\n",
        "    return np.mean(ndcg_list) if ndcg_list else 0.0\n",
        "\n",
        "def diversity_at_20(predictions, test_interactions, edition_to_genres, k=20, beta=0.5):\n",
        "    uir = _relevance_per_user_item(test_interactions)\n",
        "    pred_lists = _predictions_to_lists(predictions, n=k)\n",
        "    w_sum = sum(1.0 / log2(i + 2) for i in range(k))\n",
        "    div_list = []\n",
        "    for user, rank_list in pred_lists.items():\n",
        "        items = [ed for ed in rank_list if ed is not None][:k]\n",
        "        rels = [uir[user].get(ed, 0) for ed in items]\n",
        "        rel_tilde = [1 if r > 0 else 0 for r in rels]\n",
        "        G = [set(edition_to_genres.get(ed, [])) for ed in items]\n",
        "        S = set()\n",
        "        cov_sum = 0.0\n",
        "        for i in range(min(len(items), k)):\n",
        "            w = 1.0 / log2(i + 2)\n",
        "            if rel_tilde[i] and G[i]:\n",
        "                new_g = len(G[i] - S) / len(G[i])\n",
        "                cov_sum += w * rel_tilde[i] * new_g\n",
        "                S |= G[i]\n",
        "            elif rel_tilde[i]:\n",
        "                cov_sum += w * 0.0\n",
        "        coverage_u = cov_sum / w_sum if w_sum else 0.0\n",
        "        L = [i for i in range(min(len(items), k)) if rel_tilde[i]]\n",
        "        if len(L) < 2:\n",
        "            ild_u = 0.0\n",
        "        else:\n",
        "            def jaccard_dist(gx, gy):\n",
        "                if not gx and not gy:\n",
        "                    return 0.0\n",
        "                if not gx or not gy:\n",
        "                    return 1.0\n",
        "                inter = len(gx & gy)\n",
        "                union = len(gx | gy)\n",
        "                return 1.0 - (inter / union) if union else 0.0\n",
        "            pair_sum = 0.0\n",
        "            for ii, i in enumerate(L):\n",
        "                for j in L[ii + 1 :]:\n",
        "                    pair_sum += jaccard_dist(G[i], G[j])\n",
        "            n_pairs = len(L) * (len(L) - 1) / 2\n",
        "            ild_u = (2.0 / (len(L) * (len(L) - 1))) * pair_sum\n",
        "        div_list.append(beta * coverage_u + (1 - beta) * ild_u)\n",
        "    return np.mean(div_list) if div_list else 0.0\n",
        "\n",
        "def evaluation_score(predictions, test_interactions, edition_to_genres, alpha=0.7, beta=0.5):\n",
        "    \"\"\"\n",
        "    Score = alpha * NDCG@20 + (1 - alpha) * Diversity@20.\n",
        "    predictions: dict[user_id, list of 20 edition_ids] or DataFrame with user_id, edition_id, rank.\n",
        "    test_interactions: DataFrame with user_id, edition_id, event_type (1=wishlist, 2=read).\n",
        "    edition_to_genres: dict[edition_id, set/list of genre_ids] (or build from editions + book_genres).\n",
        "    \"\"\"\n",
        "    n = ndcg_at_20(predictions, test_interactions)\n",
        "    d = diversity_at_20(predictions, test_interactions, edition_to_genres, beta=beta)\n",
        "    return alpha * n + (1 - alpha) * d, n, d\n",
        "\n",
        "def build_edition_to_genres(editions, book_genres):\n",
        "    \"\"\"Build edition_id -> set(genre_id) from editions and book_genres.\"\"\"\n",
        "    book_to_genres = book_genres.groupby(\"book_id\")[\"genre_id\"].apply(set).to_dict()\n",
        "    edition_to_genres = {}\n",
        "    for _, row in editions.iterrows():\n",
        "        edition_to_genres[row[\"edition_id\"]] = book_to_genres.get(row[\"book_id\"], set())\n",
        "    return edition_to_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>edition_id</th>\n",
              "      <th>event_type</th>\n",
              "      <th>rating</th>\n",
              "      <th>event_ts</th>\n",
              "      <th>book_id</th>\n",
              "      <th>author_id</th>\n",
              "      <th>publication_year</th>\n",
              "      <th>age_restriction</th>\n",
              "      <th>language_id</th>\n",
              "      <th>publisher_id</th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>author_name</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>genre_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>560</td>\n",
              "      <td>1012411658</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2024-12-24 19:02:14</td>\n",
              "      <td>8387168</td>\n",
              "      <td>1085990</td>\n",
              "      <td>2024</td>\n",
              "      <td>16</td>\n",
              "      <td>119</td>\n",
              "      <td>123745</td>\n",
              "      <td>И время остановилось</td>\n",
              "      <td>Во французском Берри, краю замков и зеленых по...</td>\n",
              "      <td>Кларисса Сабар</td>\n",
              "      <td>2.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>['Современная-зарубежная-литература']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  edition_id  event_type  rating            event_ts  book_id  \\\n",
              "0      560  1012411658           2     6.0 2024-12-24 19:02:14  8387168   \n",
              "\n",
              "   author_id  publication_year  age_restriction  language_id  publisher_id  \\\n",
              "0    1085990              2024               16          119        123745   \n",
              "\n",
              "                  title                                        description  \\\n",
              "0  И время остановилось  Во французском Берри, краю замков и зеленых по...   \n",
              "\n",
              "      author_name  gender  age                            genre_names  \n",
              "0  Кларисса Сабар     2.0  9.0  ['Современная-зарубежная-литература']  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Pool initialization for CatBoost Ranker (run after defining train_df and val_df) ---\n",
        "from catboost import Pool\n",
        "\n",
        "# Use data as train and future_data as val (or set train_df, val_df explicitly)\n",
        "train_df = data.copy()\n",
        "val_df = future_data.copy()\n",
        "\n",
        "# Sort by user_id\n",
        "train_df = train_df.sort_values(\"user_id\").reset_index(drop=True)\n",
        "val_df = val_df.sort_values(\"user_id\").reset_index(drop=True)\n",
        "\n",
        "# Label: 3 = read (event_type 2), 1 = wishlist (event_type 1), 0 = no interaction\n",
        "train_df[\"label\"] = train_df[\"event_type\"].map({2: 3, 1: 1}).fillna(0).astype(int)\n",
        "val_df[\"label\"] = val_df[\"event_type\"].map({2: 3, 1: 1}).fillna(0).astype(int)\n",
        "\n",
        "# genre_names as string for text_features (CatBoost expects string)\n",
        "if \"genre_names\" in train_df.columns:\n",
        "    train_df[\"genre_names\"] = train_df[\"genre_names\"].apply(\n",
        "        lambda x: \", \".join(x) if isinstance(x, list) else (str(x) if pd.notna(x) else \"\")\n",
        "    )\n",
        "    val_df[\"genre_names\"] = val_df[\"genre_names\"].apply(\n",
        "        lambda x: \", \".join(x) if isinstance(x, list) else (str(x) if pd.notna(x) else \"\")\n",
        "    )\n",
        "\n",
        "# Feature columns (exclude identifiers, target, and event_type to avoid leakage)\n",
        "exclude = [\"user_id\", \"edition_id\", \"event_type\", \"event_ts\", \"label\"]\n",
        "cat_features = [\"author_id\", \"language_id\", \"publisher_id\", \"age_restriction\"]\n",
        "feature_cols = [c for c in train_df.columns if c not in exclude]\n",
        "assert \"event_type\" not in feature_cols, \"event_type must not be used as a feature (leakage)\"\n",
        "cat_features = [c for c in cat_features if c in feature_cols]\n",
        "text_features = [\"genre_names\", \"description\", \"title\", 'author_name'] if \"genre_names\" in feature_cols else None\n",
        "\n",
        "X_train = train_df[feature_cols].copy()\n",
        "X_val = val_df[feature_cols].copy()\n",
        "\n",
        "# Ensure event_type is never used as a feature (no leakage)\n",
        "for df in [X_train, X_val]:\n",
        "    if \"event_type\" in df.columns:\n",
        "        df.drop(columns=[\"event_type\"], inplace=True)\n",
        "\n",
        "# CatBoost requires cat_features to be int or string (no float)\n",
        "for c in cat_features:\n",
        "    X_train[c] = pd.to_numeric(X_train[c], errors=\"coerce\").fillna(-1).astype(int)\n",
        "    X_val[c] = pd.to_numeric(X_val[c], errors=\"coerce\").fillna(-1).astype(int)\n",
        "\n",
        "y_train = train_df[\"label\"]\n",
        "group_id_train = train_df[\"user_id\"]\n",
        "y_val = val_df[\"label\"]\n",
        "group_id_val = val_df[\"user_id\"]\n",
        "\n",
        "train_pool = Pool(\n",
        "    data=X_train,\n",
        "    label=y_train,\n",
        "    group_id=group_id_train,\n",
        "    cat_features=cat_features,\n",
        "    text_features=text_features,\n",
        ")\n",
        "val_pool = Pool(\n",
        "    data=X_val,\n",
        "    label=y_val,\n",
        "    group_id=group_id_val,\n",
        "    cat_features=cat_features,\n",
        "    text_features=text_features,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from catboost import CatBoostRanker\n",
        "\n",
        "task_type = \"GPU\"\n",
        "\n",
        "model = CatBoostRanker(\n",
        "    loss_function=\"YetiRank\",\n",
        "    custom_metric=[\"NDCG:top=20\", \"RecallAt:top=20\"],\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    early_stopping_rounds=50,\n",
        "    task_type=task_type,\n",
        ")\n",
        "\n",
        "model.fit(train_pool, eval_set=val_pool, verbose=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_id\n",
            "0\n",
            "\n",
            "edition_id\n",
            "0\n",
            "\n",
            "event_type\n",
            "0\n",
            "\n",
            "rating\n",
            "88236\n",
            "\n",
            "event_ts\n",
            "0\n",
            "\n",
            "book_id\n",
            "0\n",
            "\n",
            "author_id\n",
            "0\n",
            "\n",
            "publication_year\n",
            "0\n",
            "\n",
            "age_restriction\n",
            "0\n",
            "\n",
            "language_id\n",
            "0\n",
            "\n",
            "publisher_id\n",
            "0\n",
            "\n",
            "title\n",
            "0\n",
            "\n",
            "description\n",
            "3582\n",
            "\n",
            "author_name\n",
            "1141\n",
            "\n",
            "gender\n",
            "5629\n",
            "\n",
            "age\n",
            "3129\n",
            "\n",
            "genre_names\n",
            "0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for col in data.columns.to_list(): \n",
        "    print(col)\n",
        "    print(data[col].isna().sum())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 9437330,
          "sourceId": 14764518,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 296410584,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
