{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-07T17:26:35.810562Z",
          "iopub.status.busy": "2026-02-07T17:26:35.809442Z",
          "iopub.status.idle": "2026-02-07T17:26:36.223456Z",
          "shell.execute_reply": "2026-02-07T17:26:36.222178Z",
          "shell.execute_reply.started": "2026-02-07T17:26:35.810471Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# here I just load the tables so there is nothing wrong with it\n",
        "interactions = pd.read_csv(\"data/interactions.csv\")\n",
        "users = pd.read_csv(\"data/users.csv\")\n",
        "editions = pd.read_csv(\"data/editions.csv\")\n",
        "authors = pd.read_csv(\"data/authors.csv\")\n",
        "genres = pd.read_csv(\"data/genres.csv\")\n",
        "book_genres = pd.read_csv(\"data/book_genres.csv\")\n",
        "\n",
        "# Aggregate genres per book so we don't duplicate interaction rows\n",
        "book_genre_names = (\n",
        "    book_genres.merge(genres, on=\"genre_id\")\n",
        "    .groupby(\"book_id\")[\"genre_name\"]\n",
        "    .apply(list)\n",
        "    .reset_index()\n",
        ")\n",
        "book_genre_names.columns = [\"book_id\", \"genre_names\"]\n",
        "\n",
        "data = (\n",
        "    interactions\n",
        "    .merge(editions, on=\"edition_id\", how=\"left\")\n",
        "    .merge(authors, on=\"author_id\", how=\"left\")\n",
        "    .merge(users, on=\"user_id\", how=\"left\")\n",
        "    .merge(book_genre_names, on=\"book_id\", how=\"left\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import log2\n",
        "from collections import defaultdict\n",
        "\n",
        "def _relevance_per_user_item(test_interactions):\n",
        "    \"\"\"Build user_id -> {edition_id: rel}. rel=3 for read (event_type=2), rel=1 for wishlist (1); read wins if both.\"\"\"\n",
        "    uir = defaultdict(dict)\n",
        "    for _, row in test_interactions.iterrows():\n",
        "        u, i, e = row[\"user_id\"], row[\"edition_id\"], row[\"event_type\"]\n",
        "        if e == 2:\n",
        "            uir[u][i] = 3\n",
        "        elif e == 1 and uir.get(u, {}).get(i, 0) != 3:\n",
        "            uir[u][i] = 1\n",
        "        elif u not in uir or i not in uir[u]:\n",
        "            uir[u][i] = 0\n",
        "    return uir\n",
        "\n",
        "def _predictions_to_lists(predictions, n=20):\n",
        "    \"\"\"Normalize predictions to dict[user_id, list of edition_id of length n].\"\"\"\n",
        "    if isinstance(predictions, pd.DataFrame):\n",
        "        pred_lists = predictions.groupby(\"user_id\").apply(\n",
        "            lambda g: g.sort_values(\"rank\")[\"edition_id\"].tolist()\n",
        "        ).to_dict()\n",
        "    else:\n",
        "        pred_lists = dict(predictions)\n",
        "    return {u: (list(ids)[:n] + [None] * (n - len(ids)))[:n] for u, ids in pred_lists.items()}\n",
        "\n",
        "def ndcg_at_20(predictions, test_interactions, k=20):\n",
        "    \"\"\"NDCG@20: relevance from test (read=3, wishlist=1), DCG/IDCG, then NDCG per user; return mean.\"\"\"\n",
        "    uir = _relevance_per_user_item(test_interactions)\n",
        "    pred_lists = _predictions_to_lists(predictions, n=k)\n",
        "    ndcg_list = []\n",
        "    for user, rank_list in pred_lists.items():\n",
        "        rels = [uir[user].get(ed, 0) for ed in rank_list if ed is not None]\n",
        "        rels = (rels + [0] * k)[:k]\n",
        "        dcg = sum(r / log2(i + 2) for i, r in enumerate(rels))\n",
        "        ideal = sorted((r for r in uir[user].values()), reverse=True)[:k]\n",
        "        ideal = ideal + [0] * (k - len(ideal))\n",
        "        idcg = sum(r / log2(i + 2) for i, r in enumerate(ideal))\n",
        "        ndcg_list.append(dcg / idcg if idcg > 0 else 0.0)\n",
        "    return np.mean(ndcg_list) if ndcg_list else 0.0\n",
        "\n",
        "def diversity_at_20(predictions, test_interactions, edition_to_genres, k=20, beta=0.5):\n",
        "    \"\"\"Diversity@20 = beta * Coverage@20 + (1-beta) * ILD@20 (relevance-weighted).\"\"\"\n",
        "    uir = _relevance_per_user_item(test_interactions)\n",
        "    pred_lists = _predictions_to_lists(predictions, n=k)\n",
        "    w_sum = sum(1.0 / log2(i + 2) for i in range(k))\n",
        "    div_list = []\n",
        "    for user, rank_list in pred_lists.items():\n",
        "        items = [ed for ed in rank_list if ed is not None][:k]\n",
        "        rels = [uir[user].get(ed, 0) for ed in items]\n",
        "        rel_tilde = [1 if r > 0 else 0 for r in rels]\n",
        "        G = [set(edition_to_genres.get(ed, [])) for ed in items]\n",
        "        # Coverage\n",
        "        S = set()\n",
        "        cov_sum = 0.0\n",
        "        for i in range(min(len(items), k)):\n",
        "            w = 1.0 / log2(i + 2)\n",
        "            if rel_tilde[i] and G[i]:\n",
        "                new_g = len(G[i] - S) / len(G[i])\n",
        "                cov_sum += w * rel_tilde[i] * new_g\n",
        "                S |= G[i]\n",
        "            elif rel_tilde[i]:\n",
        "                cov_sum += w * 0.0\n",
        "        coverage_u = cov_sum / w_sum if w_sum else 0.0\n",
        "        # ILD over relevant positions\n",
        "        L = [i for i in range(min(len(items), k)) if rel_tilde[i]]\n",
        "        if len(L) < 2:\n",
        "            ild_u = 0.0\n",
        "        else:\n",
        "            def jaccard_dist(gx, gy):\n",
        "                if not gx and not gy:\n",
        "                    return 0.0\n",
        "                if not gx or not gy:\n",
        "                    return 1.0\n",
        "                inter = len(gx & gy)\n",
        "                union = len(gx | gy)\n",
        "                return 1.0 - (inter / union) if union else 0.0\n",
        "            pair_sum = 0.0\n",
        "            for ii, i in enumerate(L):\n",
        "                for j in L[ii + 1 :]:\n",
        "                    pair_sum += jaccard_dist(G[i], G[j])\n",
        "            n_pairs = len(L) * (len(L) - 1) / 2\n",
        "            ild_u = (2.0 / (len(L) * (len(L) - 1))) * pair_sum\n",
        "        div_list.append(beta * coverage_u + (1 - beta) * ild_u)\n",
        "    return np.mean(div_list) if div_list else 0.0\n",
        "\n",
        "def evaluation_score(predictions, test_interactions, edition_to_genres, alpha=0.7, beta=0.5):\n",
        "    \"\"\"\n",
        "    Score = alpha * NDCG@20 + (1 - alpha) * Diversity@20.\n",
        "    predictions: dict[user_id, list of 20 edition_ids] or DataFrame with user_id, edition_id, rank.\n",
        "    test_interactions: DataFrame with user_id, edition_id, event_type (1=wishlist, 2=read).\n",
        "    edition_to_genres: dict[edition_id, set/list of genre_ids] (or build from editions + book_genres).\n",
        "    \"\"\"\n",
        "    n = ndcg_at_20(predictions, test_interactions)\n",
        "    d = diversity_at_20(predictions, test_interactions, edition_to_genres, beta=beta)\n",
        "    return alpha * n + (1 - alpha) * d, n, d\n",
        "\n",
        "def build_edition_to_genres(editions, book_genres):\n",
        "    \"\"\"Build edition_id -> set(genre_id) from editions and book_genres.\"\"\"\n",
        "    book_to_genres = book_genres.groupby(\"book_id\")[\"genre_id\"].apply(set).to_dict()\n",
        "    edition_to_genres = {}\n",
        "    for _, row in editions.iterrows():\n",
        "        edition_to_genres[row[\"edition_id\"]] = book_to_genres.get(row[\"book_id\"], set())\n",
        "    return edition_to_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 9437330,
          "sourceId": 14764518,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 296410584,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
