{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-07T17:26:35.810562Z",
          "iopub.status.busy": "2026-02-07T17:26:35.809442Z",
          "iopub.status.idle": "2026-02-07T17:26:36.223456Z",
          "shell.execute_reply": "2026-02-07T17:26:36.222178Z",
          "shell.execute_reply.started": "2026-02-07T17:26:35.810471Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load tables\n",
        "interactions = pd.read_csv(\"data/interactions.csv\")  # only rows where user interacted with a book\n",
        "users = pd.read_csv(\"data/users.csv\")\n",
        "editions = pd.read_csv(\"data/editions.csv\")\n",
        "authors = pd.read_csv(\"data/authors.csv\")\n",
        "genres = pd.read_csv(\"data/genres.csv\")\n",
        "book_genres = pd.read_csv(\"data/book_genres.csv\")\n",
        "\n",
        "# 1) Genre names per book (one row per book_id)\n",
        "book_genre_names = (\n",
        "    book_genres.merge(genres, on=\"genre_id\")\n",
        "    .groupby(\"book_id\")[\"genre_name\"]\n",
        "    .apply(list)\n",
        "    .reset_index()\n",
        ")\n",
        "book_genre_names.columns = [\"book_id\", \"genre_names\"]\n",
        "\n",
        "# 2) Edition-level features (editions + authors + genres) — for merging later\n",
        "editions_enriched = (\n",
        "    editions\n",
        "    .merge(authors, on=\"author_id\", how=\"left\")\n",
        "    .merge(book_genre_names, on=\"book_id\", how=\"left\")\n",
        ")\n",
        "\n",
        "# 3) Positives: (user, edition) rows that HAVE an interaction; label 3=read, 1=wishlist\n",
        "interactions[\"label\"] = interactions[\"event_type\"].map({2: 3, 1: 1}).fillna(0).astype(int)\n",
        "positives = (\n",
        "    interactions.groupby([\"user_id\", \"edition_id\"], as_index=False)\n",
        "    .agg({\"label\": \"max\", \"event_type\": \"first\", \"rating\": \"first\", \"event_ts\": \"first\"})\n",
        ")\n",
        "\n",
        "# 4) Negatives: (user, edition) rows with NO interaction — sample per user for CatBoost Ranker\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "all_edition_ids = interactions[\"edition_id\"].unique()\n",
        "user_pos_editions = positives.groupby(\"user_id\")[\"edition_id\"].apply(set).to_dict()\n",
        "n_neg_mult = 5  # negatives per user ≈ n_neg_mult * (num positives)\n",
        "\n",
        "neg_rows = []\n",
        "for user_id, pos_eds in user_pos_editions.items():\n",
        "    neg_candidates = np.setdiff1d(all_edition_ids, np.array(list(pos_eds)))\n",
        "    n_neg = min(n_neg_mult * len(pos_eds), len(neg_candidates))\n",
        "    if n_neg > 0:\n",
        "        for ed in np.random.choice(neg_candidates, size=n_neg, replace=False):\n",
        "            neg_rows.append({\"user_id\": user_id, \"edition_id\": ed, \"label\": 0, \"event_type\": 0, \"rating\": np.nan, \"event_ts\": pd.NaT})\n",
        "negatives = pd.DataFrame(neg_rows)\n",
        "\n",
        "# 5) Combine (with-event and no-event) and merge with edition + user tables\n",
        "data = (\n",
        "    pd.concat([positives, negatives], ignore_index=True)\n",
        "    .merge(editions_enriched, on=\"edition_id\", how=\"left\")\n",
        "    .merge(users, on=\"user_id\", how=\"left\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split last month for validation; prepare data & future_data for CatBoost Ranker\n",
        "data[\"event_ts\"] = pd.to_datetime(data[\"event_ts\"])\n",
        "cutoff = data[\"event_ts\"].max() - pd.Timedelta(days=30)\n",
        "future_data = data[data[\"event_ts\"] >= cutoff].copy()\n",
        "data = data[data[\"event_ts\"] < cutoff].copy()\n",
        "\n",
        "CAT = [\"author_id\", \"language_id\", \"publisher_id\", \"age_restriction\"]\n",
        "def prep(df):\n",
        "    out = df.copy()\n",
        "    for c in out.columns:\n",
        "        if c in CAT:\n",
        "            out[c] = pd.to_numeric(out[c], errors=\"coerce\").fillna(-1).astype(int)\n",
        "        elif out[c].dtype == object or pd.api.types.is_string_dtype(out[c]):\n",
        "            out[c] = out[c].fillna(\"missing\").astype(str).replace(\"nan\", \"missing\")\n",
        "        elif pd.api.types.is_integer_dtype(out[c]):\n",
        "            out[c] = out[c].fillna(-1)\n",
        "        else:\n",
        "            out[c] = out[c].fillna(0.0)\n",
        "    return out\n",
        "data, future_data = prep(data), prep(future_data)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 9437330,
          "sourceId": 14764518,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 296410584,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
