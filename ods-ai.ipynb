{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-07T17:26:35.810562Z",
          "iopub.status.busy": "2026-02-07T17:26:35.809442Z",
          "iopub.status.idle": "2026-02-07T17:26:36.223456Z",
          "shell.execute_reply": "2026-02-07T17:26:36.222178Z",
          "shell.execute_reply.started": "2026-02-07T17:26:35.810471Z"
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interactions = pd.read_csv(\"data/interactions.csv\")\n",
        "users = pd.read_csv(\"data/users.csv\")\n",
        "editions = pd.read_csv(\"data/editions.csv\")\n",
        "authors = pd.read_csv(\"data/authors.csv\")\n",
        "genres = pd.read_csv(\"data/genres.csv\")\n",
        "book_genres = pd.read_csv(\"data/book_genres.csv\")\n",
        "\n",
        "book_genre_names = (\n",
        "    book_genres.merge(genres, on=\"genre_id\")\n",
        "    .groupby(\"book_id\")[\"genre_name\"]\n",
        "    .apply(list)\n",
        "    .reset_index()\n",
        ")\n",
        "book_genre_names.columns = [\"book_id\", \"genre_names\"]\n",
        "\n",
        "data = (\n",
        "    interactions\n",
        "    .merge(editions, on=\"edition_id\", how=\"left\")\n",
        "    .merge(authors, on=\"author_id\", how=\"left\")\n",
        "    .merge(users, on=\"user_id\", how=\"left\")\n",
        "    .merge(book_genre_names, on=\"book_id\", how=\"left\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data[\"event_ts\"] = pd.to_datetime(data[\"event_ts\"])\n",
        "max_ts = data[\"event_ts\"].max()\n",
        "cutoff_ts = max_ts - pd.Timedelta(days=30)\n",
        "future_data = data[data[\"event_ts\"] >= cutoff_ts].copy()\n",
        "data = data[data[\"event_ts\"] < cutoff_ts].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from math import log2\n",
        "from collections import defaultdict\n",
        "\n",
        "def _relevance_per_user_item(test_interactions):\n",
        "    uir = defaultdict(dict)\n",
        "    for _, row in test_interactions.iterrows():\n",
        "        u, i, e = row[\"user_id\"], row[\"edition_id\"], row[\"event_type\"]\n",
        "        if e == 2:\n",
        "            uir[u][i] = 3\n",
        "        elif e == 1 and uir.get(u, {}).get(i, 0) != 3:\n",
        "            uir[u][i] = 1\n",
        "        elif u not in uir or i not in uir[u]:\n",
        "            uir[u][i] = 0\n",
        "    return uir\n",
        "\n",
        "def _predictions_to_lists(predictions, n=20):\n",
        "    if isinstance(predictions, pd.DataFrame):\n",
        "        pred_lists = predictions.groupby(\"user_id\").apply(\n",
        "            lambda g: g.sort_values(\"rank\")[\"edition_id\"].tolist()\n",
        "        ).to_dict()\n",
        "    else:\n",
        "        pred_lists = dict(predictions)\n",
        "    return {u: (list(ids)[:n] + [None] * (n - len(ids)))[:n] for u, ids in pred_lists.items()}\n",
        "\n",
        "def ndcg_at_20(predictions, test_interactions, k=20):\n",
        "    uir = _relevance_per_user_item(test_interactions)\n",
        "    pred_lists = _predictions_to_lists(predictions, n=k)\n",
        "    ndcg_list = []\n",
        "    for user, rank_list in pred_lists.items():\n",
        "        rels = [uir[user].get(ed, 0) for ed in rank_list if ed is not None]\n",
        "        rels = (rels + [0] * k)[:k]\n",
        "        dcg = sum(r / log2(i + 2) for i, r in enumerate(rels))\n",
        "        ideal = sorted((r for r in uir[user].values()), reverse=True)[:k]\n",
        "        ideal = ideal + [0] * (k - len(ideal))\n",
        "        idcg = sum(r / log2(i + 2) for i, r in enumerate(ideal))\n",
        "        ndcg_list.append(dcg / idcg if idcg > 0 else 0.0)\n",
        "    return np.mean(ndcg_list) if ndcg_list else 0.0\n",
        "\n",
        "def diversity_at_20(predictions, test_interactions, edition_to_genres, k=20, beta=0.5):\n",
        "    uir = _relevance_per_user_item(test_interactions)\n",
        "    pred_lists = _predictions_to_lists(predictions, n=k)\n",
        "    w_sum = sum(1.0 / log2(i + 2) for i in range(k))\n",
        "    div_list = []\n",
        "    for user, rank_list in pred_lists.items():\n",
        "        items = [ed for ed in rank_list if ed is not None][:k]\n",
        "        rels = [uir[user].get(ed, 0) for ed in items]\n",
        "        rel_tilde = [1 if r > 0 else 0 for r in rels]\n",
        "        G = [set(edition_to_genres.get(ed, [])) for ed in items]\n",
        "        S = set()\n",
        "        cov_sum = 0.0\n",
        "        for i in range(min(len(items), k)):\n",
        "            w = 1.0 / log2(i + 2)\n",
        "            if rel_tilde[i] and G[i]:\n",
        "                new_g = len(G[i] - S) / len(G[i])\n",
        "                cov_sum += w * rel_tilde[i] * new_g\n",
        "                S |= G[i]\n",
        "            elif rel_tilde[i]:\n",
        "                cov_sum += w * 0.0\n",
        "        coverage_u = cov_sum / w_sum if w_sum else 0.0\n",
        "        L = [i for i in range(min(len(items), k)) if rel_tilde[i]]\n",
        "        if len(L) < 2:\n",
        "            ild_u = 0.0\n",
        "        else:\n",
        "            def jaccard_dist(gx, gy):\n",
        "                if not gx and not gy:\n",
        "                    return 0.0\n",
        "                if not gx or not gy:\n",
        "                    return 1.0\n",
        "                inter = len(gx & gy)\n",
        "                union = len(gx | gy)\n",
        "                return 1.0 - (inter / union) if union else 0.0\n",
        "            pair_sum = 0.0\n",
        "            for ii, i in enumerate(L):\n",
        "                for j in L[ii + 1 :]:\n",
        "                    pair_sum += jaccard_dist(G[i], G[j])\n",
        "            n_pairs = len(L) * (len(L) - 1) / 2\n",
        "            ild_u = (2.0 / (len(L) * (len(L) - 1))) * pair_sum\n",
        "        div_list.append(beta * coverage_u + (1 - beta) * ild_u)\n",
        "    return np.mean(div_list) if div_list else 0.0\n",
        "\n",
        "def evaluation_score(predictions, test_interactions, edition_to_genres, alpha=0.7, beta=0.5):\n",
        "    \"\"\"\n",
        "    Score = alpha * NDCG@20 + (1 - alpha) * Diversity@20.\n",
        "    predictions: dict[user_id, list of 20 edition_ids] or DataFrame with user_id, edition_id, rank.\n",
        "    test_interactions: DataFrame with user_id, edition_id, event_type (1=wishlist, 2=read).\n",
        "    edition_to_genres: dict[edition_id, set/list of genre_ids] (or build from editions + book_genres).\n",
        "    \"\"\"\n",
        "    n = ndcg_at_20(predictions, test_interactions)\n",
        "    d = diversity_at_20(predictions, test_interactions, edition_to_genres, beta=beta)\n",
        "    return alpha * n + (1 - alpha) * d, n, d\n",
        "\n",
        "def build_edition_to_genres(editions, book_genres):\n",
        "    \"\"\"Build edition_id -> set(genre_id) from editions and book_genres.\"\"\"\n",
        "    book_to_genres = book_genres.groupby(\"book_id\")[\"genre_id\"].apply(set).to_dict()\n",
        "    edition_to_genres = {}\n",
        "    for _, row in editions.iterrows():\n",
        "        edition_to_genres[row[\"edition_id\"]] = book_to_genres.get(row[\"book_id\"], set())\n",
        "    return edition_to_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Pool initialization for CatBoost Ranker (run after defining train_df and val_df) ---\n",
        "from catboost import Pool\n",
        "\n",
        "# Use data as train and future_data as val (or set train_df, val_df explicitly)\n",
        "train_df = data.copy()\n",
        "val_df = future_data.copy()\n",
        "\n",
        "# Sort by user_id\n",
        "train_df = train_df.sort_values(\"user_id\").reset_index(drop=True)\n",
        "val_df = val_df.sort_values(\"user_id\").reset_index(drop=True)\n",
        "\n",
        "# Label: 3 = read (event_type 2), 1 = wishlist (event_type 1), 0 = no interaction\n",
        "train_df[\"label\"] = train_df[\"event_type\"].map({2: 3, 1: 1}).fillna(0).astype(int)\n",
        "val_df[\"label\"] = val_df[\"event_type\"].map({2: 3, 1: 1}).fillna(0).astype(int)\n",
        "\n",
        "# genre_names as string for text_features (CatBoost expects string)\n",
        "if \"genre_names\" in train_df.columns:\n",
        "    train_df[\"genre_names\"] = train_df[\"genre_names\"].apply(\n",
        "        lambda x: \", \".join(x) if isinstance(x, list) else (str(x) if pd.notna(x) else \"\")\n",
        "    )\n",
        "    val_df[\"genre_names\"] = val_df[\"genre_names\"].apply(\n",
        "        lambda x: \", \".join(x) if isinstance(x, list) else (str(x) if pd.notna(x) else \"\")\n",
        "    )\n",
        "\n",
        "# Feature columns (exclude identifiers and target)\n",
        "exclude = [\"user_id\", \"edition_id\", \"event_type\", \"event_ts\", \"label\"]\n",
        "cat_features = [\"author_id\", \"language_id\", \"publisher_id\", \"age_restriction\"]\n",
        "feature_cols = [c for c in train_df.columns if c not in exclude]\n",
        "cat_features = [c for c in cat_features if c in feature_cols]\n",
        "text_features = [\"genre_names\"] if \"genre_names\" in feature_cols else None\n",
        "\n",
        "X_train = train_df[feature_cols]\n",
        "y_train = train_df[\"label\"]\n",
        "group_id_train = train_df[\"user_id\"]\n",
        "\n",
        "X_val = val_df[feature_cols]\n",
        "y_val = val_df[\"label\"]\n",
        "group_id_val = val_df[\"user_id\"]\n",
        "\n",
        "train_pool = Pool(\n",
        "    data=X_train,\n",
        "    label=y_train,\n",
        "    group_id=group_id_train,\n",
        "    cat_features=cat_features,\n",
        "    text_features=text_features,\n",
        ")\n",
        "val_pool = Pool(\n",
        "    data=X_val,\n",
        "    label=y_val,\n",
        "    group_id=group_id_val,\n",
        "    cat_features=cat_features,\n",
        "    text_features=text_features,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- CatBoost Ranker: train and return model ---\n",
        "from catboost import CatBoostRanker\n",
        "\n",
        "# Use GPU if available; set to \"CPU\" if you get GPU-related errors\n",
        "task_type = \"GPU\"\n",
        "\n",
        "model = CatBoostRanker(\n",
        "    loss_function=\"YetiRank\",\n",
        "    custom_metric=[\"NDCG:top=20\", \"RecallAt:top=20\"],\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    early_stopping_rounds=50,\n",
        "    task_type=task_type,\n",
        ")\n",
        "\n",
        "model.fit(train_pool, eval_set=val_pool, verbose=50)\n",
        "# model is the trained CatBoostRanker instance"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 9437330,
          "sourceId": 14764518,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 296410584,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
