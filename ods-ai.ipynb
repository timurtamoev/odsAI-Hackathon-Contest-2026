{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation - we create one BIG table that has all user's possible interactions and negative objects - user <-> book when there was no interaction \\\\\n",
        "therfore I am gonna fit catboost ranker with it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "interactions = pd.read_csv(\"/kaggle/input/datasets/timrachlin/ods-ai-hacktahon/participants/data/interactions.csv\")\n",
        "users = pd.read_csv(\"/kaggle/input/datasets/timrachlin/ods-ai-hacktahon/participants/data/users.csv\")\n",
        "editions = pd.read_csv(\"/kaggle/input/datasets/timrachlin/ods-ai-hacktahon/participants/data/editions.csv\")\n",
        "authors = pd.read_csv(\"/kaggle/input/datasets/timrachlin/ods-ai-hacktahon/participants/data/authors.csv\")\n",
        "genres = pd.read_csv(\"/kaggle/input/datasets/timrachlin/ods-ai-hacktahon/participants/data/genres.csv\")\n",
        "book_genres = pd.read_csv(\"/kaggle/input/datasets/timrachlin/ods-ai-hacktahon/participants/data/book_genres.csv\")\n",
        "\n",
        "# 1) Genre names per book\n",
        "book_genre_names = (\n",
        "    book_genres.merge(genres, on=\"genre_id\")\n",
        "    .groupby(\"book_id\")[\"genre_name\"]\n",
        "    .apply(list)\n",
        "    .reset_index()\n",
        ")\n",
        "book_genre_names.columns = [\"book_id\", \"genre_names\"]\n",
        "\n",
        "# 2) Edition-level features\n",
        "editions_enriched = (\n",
        "    editions\n",
        "    .merge(authors, on=\"author_id\", how=\"left\")\n",
        "    .merge(book_genre_names, on=\"book_id\", how=\"left\")\n",
        ")\n",
        "\n",
        "# 3) Positives\n",
        "interactions[\"label\"] = interactions[\"event_type\"].map({2: 3, 1: 1}).fillna(0).astype(int)\n",
        "positives = (\n",
        "    interactions.groupby([\"user_id\", \"edition_id\"], as_index=False)\n",
        "    .agg({\"label\": \"max\"})  # только label, без event_type/rating/event_ts\n",
        ")\n",
        "\n",
        "# 4) Negatives — только user_id, edition_id, label=0, без event-фичей\n",
        "np.random.seed(42)\n",
        "all_edition_ids = interactions[\"edition_id\"].unique()\n",
        "user_pos_editions = positives.groupby(\"user_id\")[\"edition_id\"].apply(set).to_dict()\n",
        "n_neg_mult = 5\n",
        "\n",
        "neg_rows = []\n",
        "for user_id, pos_eds in user_pos_editions.items():\n",
        "    neg_candidates = np.setdiff1d(all_edition_ids, np.array(list(pos_eds)))\n",
        "    n_neg = min(n_neg_mult * len(pos_eds), len(neg_candidates))\n",
        "    if n_neg > 0:\n",
        "        for ed in np.random.choice(neg_candidates, size=n_neg, replace=False):\n",
        "            neg_rows.append({\"user_id\": user_id, \"edition_id\": ed, \"label\": 0})\n",
        "negatives = pd.DataFrame(neg_rows)\n",
        "\n",
        "# 5) Combine и merge с фичами книг и юзеров\n",
        "data = (\n",
        "    pd.concat([positives, negatives], ignore_index=True)\n",
        "    .merge(editions_enriched, on=\"edition_id\", how=\"left\")\n",
        "    .merge(users, on=\"user_id\", how=\"left\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from catboost import Pool\n",
        "\n",
        "# 1. Сортируем данные (для групп)\n",
        "train_df = data.sort_values(\"user_id\").reset_index(drop=True)\n",
        "\n",
        "# 2. ИСКЛЮЧАЕМ ЛИШНЕЕ. Самый важный момент.\n",
        "# Убираем все ID и ответы (label, rating) из признаков\n",
        "exclude = [\"user_id\", \"edition_id\", \"event_type\", \"label\", \"rating\"]\n",
        "feature_cols = [c for c in train_df.columns if c not in exclude]\n",
        "\n",
        "# 3. Определяем типы признаков\n",
        "cat_features = [c for c in [\"author_id\", \"language_id\", \"publisher_id\", \"age_restriction\"] if c in feature_cols]\n",
        "text_features = [c for c in feature_cols if train_df[c].dtype == object or pd.api.types.is_string_dtype(train_df[c])]\n",
        "\n",
        "if not text_features:\n",
        "    text_features = None\n",
        "\n",
        "# 4. Чистим текст (заполняем пропуски)\n",
        "if text_features:\n",
        "    for c in text_features:\n",
        "        train_df[c] = train_df[c].apply(lambda x: \", \".join(x) if isinstance(x, list) else (str(x) if pd.notna(x) else \"missing\"))\n",
        "\n",
        "# 5. Создаем матрицу X_train\n",
        "X_train = train_df[feature_cols].copy()\n",
        "\n",
        "# Обрабатываем категории (CatBoost нужен int или str, но лучше int с -1 для пропусков)\n",
        "for c in cat_features:\n",
        "    X_train[c] = pd.to_numeric(X_train[c], errors=\"coerce\").fillna(-1).astype(int)\n",
        "\n",
        "# 6. Создаем Pool\n",
        "# В data кладем ТОЛЬКО признаки (без label/user_id), а label и group_id передаем отдельными аргументами\n",
        "train_pool = Pool(\n",
        "    data=X_train, \n",
        "    label=train_df[\"label\"], \n",
        "    group_id=train_df[\"user_id\"], \n",
        "    cat_features=cat_features, \n",
        "    text_features=text_features\n",
        ")\n",
        "\n",
        "print(f\"Pool готов. Признаков: {len(feature_cols)}. Колонка 'label' в признаки НЕ входит.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from catboost import CatBoostRanker\n",
        "\n",
        "tt = 'CPU' # Или 'GPU', как у тебя настроено\n",
        "\n",
        "model = CatBoostRanker(\n",
        "    loss_function=\"YetiRank\",\n",
        "    custom_metric=[\"NDCG:top=20\"],\n",
        "    iterations=1000,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    early_stopping_rounds=50, # Сработает только если есть eval_set, но пусть остается, не мешает\n",
        "    task_type=tt,\n",
        "    verbose=50\n",
        ")\n",
        "\n",
        "# Обучаем на всем пуле, без валидации\n",
        "model.fit(train_pool)\n",
        "model.save_model(\"trained_ranker_model.cbm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict scores and add to dataframes; concatenate into one\n",
        "train_df[\"score\"] = model.predict(X_train)\n",
        "val_df[\"score\"] = model.predict(X_val)\n",
        "data_with_scores = pd.concat([train_df, val_df], ignore_index=True)"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 9437330,
          "sourceId": 14764518,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 296410584,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 31259,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
